{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Liver Disease Predictor.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxzXFLR/m0B61YegLc5+MH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharineeshramtp2000/Support-Vector-Machine-Classification---Liver-Disease-Prediction/blob/master/Liver_Disease_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeaUi3cXjJ6",
        "colab_type": "text"
      },
      "source": [
        "Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gG7dpoXchH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1EEG2XqUH",
        "colab_type": "text"
      },
      "source": [
        "Importing the Dataset. Here we use the dataset from [ML Data](https://www.mldata.io/datasets/).\n",
        "![](https://www.health.harvard.edu/media/content/images/p3_InjuredLiver_W1907_gi937610338.jpg)\n",
        "---\n",
        "The dataset consists of \n",
        "1.  age\tinteger\tAge of the patient in years\n",
        "2.  gender\tstring\tPatient Gender: Male or Female\n",
        "3.  TB\tfloat\tTotal Bilirubin\n",
        "4.  DB\tfloat\tDirect Bilirubin\n",
        "5.  alkphos\tfloat\tAlkaline Phosphotase\n",
        "6.  sgpt\tfloat\tAlamine Aminotransferase\n",
        "7.  sgot\tfloat\tAspartate Aminotransferase\n",
        "8.  TP\tfloat\tTotal Proteins\n",
        "9.  ALB\tfloat\tAlbumin\n",
        "10. A_G\tfloat\tRatio of Albumin and Globulin\n",
        "11. class\tfloat\tPredictor Class: 1 if patient has Liver Disease and 2 if they do not\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifsPeCMYo2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "faae9913-37a7-48d4-937d-6210e790a1ae"
      },
      "source": [
        "Dataset = pd.read_csv(\"indian_liver_patient_dataset.csv\")\n",
        "X = Dataset.iloc[:,:-1].values\n",
        "y = Dataset.iloc[:, -1].values\n",
        "Dataset.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>TB</th>\n",
              "      <th>DB</th>\n",
              "      <th>alkphos</th>\n",
              "      <th>sgpt</th>\n",
              "      <th>sgot</th>\n",
              "      <th>TP</th>\n",
              "      <th>ALB</th>\n",
              "      <th>A_G</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.000000</td>\n",
              "      <td>583.00000</td>\n",
              "      <td>583.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>44.746141</td>\n",
              "      <td>3.298799</td>\n",
              "      <td>1.486106</td>\n",
              "      <td>290.576329</td>\n",
              "      <td>80.713551</td>\n",
              "      <td>109.910806</td>\n",
              "      <td>6.483190</td>\n",
              "      <td>3.141852</td>\n",
              "      <td>-685.16578</td>\n",
              "      <td>1.286449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.189833</td>\n",
              "      <td>6.209522</td>\n",
              "      <td>2.808498</td>\n",
              "      <td>242.937989</td>\n",
              "      <td>182.620356</td>\n",
              "      <td>288.918529</td>\n",
              "      <td>1.085451</td>\n",
              "      <td>0.795519</td>\n",
              "      <td>8261.85600</td>\n",
              "      <td>0.452490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>-100000.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>175.500000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.70000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>3.100000</td>\n",
              "      <td>0.92000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>298.000000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>1.10000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>19.700000</td>\n",
              "      <td>2110.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>4929.000000</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>2.80000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age          TB          DB  ...         ALB           A_G       class\n",
              "count  583.000000  583.000000  583.000000  ...  583.000000     583.00000  583.000000\n",
              "mean    44.746141    3.298799    1.486106  ...    3.141852    -685.16578    1.286449\n",
              "std     16.189833    6.209522    2.808498  ...    0.795519    8261.85600    0.452490\n",
              "min      4.000000    0.400000    0.100000  ...    0.900000 -100000.00000    1.000000\n",
              "25%     33.000000    0.800000    0.200000  ...    2.600000       0.70000    1.000000\n",
              "50%     45.000000    1.000000    0.300000  ...    3.100000       0.92000    1.000000\n",
              "75%     58.000000    2.600000    1.300000  ...    3.800000       1.10000    2.000000\n",
              "max     90.000000   75.000000   19.700000  ...    5.500000       2.80000    2.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz108lTlrQng",
        "colab_type": "text"
      },
      "source": [
        "Here in the dataset, one of the attribute is sex, given as 'Male' and 'Female'. We need to convert these strings into binary values(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_9GzLrxrPSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X = LabelEncoder()\n",
        "X[:,1] = labelencoder_X.fit_transform(X[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbg5jOhBYx2V",
        "colab_type": "text"
      },
      "source": [
        "Now lets feature scale our independent variables from our famous [scikit](https://scikit-learn.org/stable/) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Widc4BbzZNvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X[:,[0,2,3,4,5,6,7,8,9]] = sc_X.fit_transform(X[:,[0,2,3,4,5,6,7,8,9]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CaoxRcZeMd",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset into training and testing and performing a good shuffle of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP83grDqZlOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82SIY2PZmNj",
        "colab_type": "text"
      },
      "source": [
        "Now lets define our SVM Classification model.\n",
        "We use the Gaussian Kernel which is most commonly preferred.\n",
        "Apart from that we define the constant C so that the hyperplane best fits for our train and test data.\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*c_JJszZ8GlnQ7kx88Z2TeA.png)\n",
        "\n",
        "Feel free to use the [Documnetaton for Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bLh52NbAxk",
        "colab_type": "code",
        "outputId": "2c9d43c9-ac0c-4033-c3a0-469671a837da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(C = 10.0, kernel = 'rbf',decision_function_shape='ono')\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ono', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j8E0L4b78d",
        "colab_type": "text"
      },
      "source": [
        "Now lets predict with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMBI0Utb_rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1xGFcQIcDJv",
        "colab_type": "text"
      },
      "source": [
        "Its time for evaluating our model.\n",
        "\n",
        "![](https://www.thinkebiz.net/wp-content/uploads/2018/01/74228032_s.jpg)\n",
        "\n",
        "---\n",
        "Lets first predict how our model is fitting for our training set\n",
        "We use the famous\n",
        "1.   f1 score\n",
        "2.   accuracy \n",
        "to evaluate the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjsrO7ycCIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AodntoNGc62e",
        "colab_type": "code",
        "outputId": "bd5f846e-ecca-42a9-b4e9-6c41fa86bb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_train = accuracy_score(y_train, classifier.predict(X_train))\n",
        "f1_train = f1_score(y_train, classifier.predict(X_train), average= 'weighted')\n",
        "\n",
        "print(\"Traing set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_train)\n",
        "print(\"F1 SCORE ---------------------->\",f1_train)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing set results\n",
            "ACCURACY ----------------------> 0.7573529411764706\n",
            "F1 SCORE ----------------------> 0.7105043102792938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGihP6W9d3-E",
        "colab_type": "text"
      },
      "source": [
        "Now lets see how well is our model. So now lets evaluate with our test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjgDCMbeCql",
        "colab_type": "code",
        "outputId": "34c162ba-7715-41ea-8b57-d8ece9a0ac3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "f1_test = f1_score(y_test, y_pred, average= 'weighted')\n",
        "\n",
        "print(\"Test set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_test)\n",
        "print(\"F1 SCORE ---------------------->\",f1_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results\n",
            "ACCURACY ----------------------> 0.7257142857142858\n",
            "F1 SCORE ----------------------> 0.6859216878240657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2cFvHYehTh",
        "colab_type": "text"
      },
      "source": [
        "Now lets have our famous Confusion Matrix to visually understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MWd1w8etjW",
        "colab_type": "code",
        "outputId": "e1a4bb75-b280-4875-d49d-b2b39f1915db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[117  11]\n",
            " [ 37  10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQxBHanoex-e",
        "colab_type": "text"
      },
      "source": [
        "Our model has worked well with our test set too.\n",
        "The **accuaracy** and **f1 score** for both test and training set is good.\n",
        "Its always to put a question and ask to ourselves that is this the best model?\n",
        "\n",
        "---\n",
        "\n",
        "Obvisouly not!\n",
        "We can still achive our accuracy by changing our models, changing the independent variables, change the metrics and so on.\n",
        "Its great that we have successfully implemented SVM classification with our Liver Disease Dataset.\n"
      ]
    }
  ]
}